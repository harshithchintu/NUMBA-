{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **NUMBA**\n",
        "[NUMBA Documentation](https://numba.readthedocs.io/en/stable/)"
      ],
      "metadata": {
        "id": "8neLD6jJjMU5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is NUMBA?**\n",
        "\n",
        "NUMBA is a powerful Python library used for optimizing and accelerating numerical computations. It specializes in just-in-time (JIT) compilation, which means it translates Python functions into machine code at runtime, leading to significant speedups compared to traditional Python execution."
      ],
      "metadata": {
        "id": "eh1YZ3LvjlVv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Key Features:**\n",
        "\n",
        "1. Just-in-Time (JIT) Compilation: NUMBA dynamically compiles Python functions to machine code, resulting in faster execution. This is particularly beneficial for numerical computations where performance is crucial.\n",
        "2. Decorators for Function Acceleration: NUMBA provides decorators like @jit that you can apply to Python functions to instruct NUMBA to compile them for optimized performance.\n",
        "3. Support for Numerical Types: NUMBA supports various numerical types such as integers, floats, and complex numbers.\n",
        "4. Integration with NumPy: NUMBA seamlessly integrates with NumPy, a popular numerical computing library in Python. This means one can accelerate their existing NumPy code by adding NUMBA decorators to their functions.\n",
        "5. Parallel Execution: NUMBA supports parallel execution of code on multiple CPU cores or even GPUs. This enables the user to take advantage of parallelism to further speed up their computations, especially for tasks involving large datasets or complex algorithms.\n",
        "6. Ease of Use: NUMBA is easy to use with basic python knowledge."
      ],
      "metadata": {
        "id": "8JqSF1aPoqOp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Installation**"
      ],
      "metadata": {
        "id": "CEnf6QcVCtta"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "pip install numba\n",
        "\n",
        "This should help setting up the environment to use Numba\n"
      ],
      "metadata": {
        "id": "55TTfhRiC416"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Diagnostics in NUMBA**"
      ],
      "metadata": {
        "id": "pl3i7VElpIeP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Numba Diagnostics](https://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics)"
      ],
      "metadata": {
        "id": "hxyt1W2vhjr9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is Diagnostics?**\n",
        "\n",
        "Diagnostic is a useful tool and feature provided by NUMBA to analyze and optimize the performace of compiled code. A feature of Numba, Profiling which helps in identifying errors and debugging the code. Diagnostics usually is helpful in troubleshooting any issues that arise during compilation or execution."
      ],
      "metadata": {
        "id": "c44lslqtiRLF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Use of Diagnostics**\n",
        "\n",
        "\n",
        "\n",
        "1. Profiling - This includes measuring execution times of functions and understanding memory usage.\n",
        "2. Meaningful error messages - This includes providing informative error messages and warnings during compilation and execution.\n",
        "3. Debugging - This includes debugging code by providing information about the compilation process, including line numbers, variable types, and optimization stages.\n",
        "\n"
      ],
      "metadata": {
        "id": "GwUvmrL9r1Vh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YB7eW72vw9sJ",
        "outputId": "020f412b-9a58-4b74-dc22-b81576dfb41f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "\n",
        "A = np.random.rand(100, 100)\n",
        "B = np.random.rand(100, 100)\n",
        "C = np.zeros((100, 100))\n",
        "\n",
        "start_time = time.time()\n",
        "num_executions = 0\n",
        "\n",
        "for i in range(100):\n",
        "    for j in range(100):\n",
        "        for k in range(100):\n",
        "            C[i][j] += A[i][k] * B[k][j]\n",
        "            num_executions += 1\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(\"Number of executions of the line of code:\", num_executions)\n",
        "print(\"Execution time: {:.6f} seconds\".format(execution_time))"
      ],
      "metadata": {
        "id": "UCKDdqWtkWlL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10efae98-b8a4-4fe4-d5e4-3482d8ab7858"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of executions of the line of code: 1000000\n",
            "Execution time: 1.973450 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Sample Code using for loops without python compiler**"
      ],
      "metadata": {
        "id": "fZi0fr2kDBYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numba import prange, jit\n",
        "import time\n",
        "\n",
        "@jit(nopython=True, parallel=True)\n",
        "def matrix_mul(A, B):\n",
        "    rows_A, cols_A = A.shape\n",
        "    rows_B, cols_B = B.shape\n",
        "\n",
        "    C = np.zeros((rows_A, cols_B))\n",
        "\n",
        "    for i in prange(rows_A):\n",
        "        for j in prange(cols_B):\n",
        "            for k in prange(cols_A):\n",
        "                C[i][j] += A[i][k] * B[k][j]\n",
        "    return C\n",
        "\n",
        "start_time = time.time()\n",
        "A = np.random.rand(5, 5)\n",
        "B = np.random.rand(5, 5)\n",
        "C = matrix_mul(A, B)\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(\"Execution time: {:.6f} seconds\".format(execution_time))\n",
        "print('\\nResult: \\n', C)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNSLzzE_4Ean",
        "outputId": "cf6948f2-75d9-4a3d-caa1-94b3f5fbc67b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution time: 1.114748 seconds\n",
            "\n",
            "Result: \n",
            " [[1.66523292 1.44073188 1.50643627 1.25258289 0.79583439]\n",
            " [2.04264979 1.81689585 1.82406899 1.58781296 1.52281961]\n",
            " [1.30247635 1.27670653 1.27587483 1.00976042 1.08711463]\n",
            " [2.67430027 2.42565991 2.5245097  2.08145241 1.89493203]\n",
            " [1.57343789 1.46454058 1.34209443 1.20051057 1.1092336 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Sample code using for loops with Python compiler**"
      ],
      "metadata": {
        "id": "wGuMw4Tdmo9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numba import prange, jit\n",
        "import time\n",
        "\n",
        "@jit(nopython=False, parallel=True)\n",
        "def matrix_mul(A, B):\n",
        "  rows_A, cols_A = A.shape\n",
        "  rows_B, cols_B = B.shape\n",
        "\n",
        "  C = np.zeros((rows_A, cols_B))\n",
        "\n",
        "  for i in prange(rows_A):\n",
        "    for j in prange(cols_B):\n",
        "      for k in prange(cols_A):\n",
        "        C[i][j] += A[i][k] * B[k][j]\n",
        "\n",
        "  return C\n",
        "\n",
        "start_time = time.time()\n",
        "A = np.random.rand(5, 5)\n",
        "B = np.random.rand(5, 5)\n",
        "C = matrix_mul(A, B)\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(\"Execution time: {:.6f} seconds\".format(execution_time))\n",
        "print('\\nResult: \\n', C)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgTRwo-Ea02T",
        "outputId": "510dace2-b1ae-441a-fa37-287d315d9753"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-161562f12ac7>:5: NumbaDeprecationWarning: The keyword argument 'nopython=False' was supplied. From Numba 0.59.0 the default is being changed to True and use of 'nopython=False' will raise a warning as the argument will have no effect. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
            "  @jit(nopython=False, parallel=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution time: 1.079202 seconds\n",
            "\n",
            "Result: \n",
            " [[2.35990832 1.10290646 1.52361174 1.30498967 1.89225645]\n",
            " [1.77751358 0.81817857 1.03788781 1.05353666 1.04390853]\n",
            " [1.27849061 0.67481473 0.90808839 0.8843647  0.95246578]\n",
            " [2.21154523 0.97375101 1.09121882 1.33523135 1.30408477]\n",
            " [2.93460294 1.4905548  1.76861435 1.77684032 2.20153892]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here in this above code the Numba decorator @jit has the keywords nopython and parallel, which represents if the code needs to use the python compiler while compiling and how the compiler needs to run"
      ],
      "metadata": {
        "id": "at-4YrGaDvbv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Using Prange**"
      ],
      "metadata": {
        "id": "H92DWHsO_W9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cProfile\n",
        "import numpy as np\n",
        "from numba import prange, jit\n",
        "import time\n",
        "\n",
        "@jit(nopython=True, parallel=True)\n",
        "def matrix_mul(A, B):\n",
        "  rows_A, cols_A = A.shape\n",
        "  rows_B, cols_B = B.shape\n",
        "\n",
        "  C = np.zeros((rows_A, cols_B))\n",
        "\n",
        "  for i in prange(rows_A):\n",
        "    for j in prange(cols_B):\n",
        "      for k in prange(cols_A):\n",
        "        C[i][j] += A[i][k] * B[k][j]\n",
        "\n",
        "  return C\n",
        "\n",
        "start_time = time.time()\n",
        "A = np.random.rand(5, 5)\n",
        "B = np.random.rand(5, 5)\n",
        "C = matrix_mul(A, B)\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(\"Execution time: {:.6f} seconds\".format(execution_time))\n",
        "print('\\nResult: \\n', C)\n",
        "cProfile.run('matrix_mul(A, B)')"
      ],
      "metadata": {
        "id": "0yz8rhsY_cLA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b5364b4-83ac-4e89-ed4d-1386309b8da3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution time: 0.960954 seconds\n",
            "\n",
            "Result: \n",
            " [[1.32957628 1.43724936 1.20425947 0.68876728 1.26749742]\n",
            " [1.27157914 1.58222414 0.56477194 0.67318835 1.07186891]\n",
            " [1.21219102 1.55435008 0.57961429 0.58149866 0.89090795]\n",
            " [1.12536815 1.46023993 0.61263766 0.78507714 1.01741634]\n",
            " [1.66955412 1.91579661 0.74602997 0.92502417 1.52828929]]\n",
            "         5 function calls in 0.000 seconds\n",
            "\n",
            "   Ordered by: standard name\n",
            "\n",
            "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
            "        1    0.000    0.000    0.000    0.000 <ipython-input-15-e5eae5ba16fd>:6(matrix_mul)\n",
            "        1    0.000    0.000    0.000    0.000 <string>:1(<module>)\n",
            "        1    0.000    0.000    0.000    0.000 serialize.py:30(_numba_unpickle)\n",
            "        1    0.000    0.000    0.000    0.000 {built-in method builtins.exec}\n",
            "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install line_profiler"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysqdDPN9xMTr",
        "outputId": "0045ca6d-abec-4050-d01e-90522632e50e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: line_profiler in /usr/local/lib/python3.10/dist-packages (4.1.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile harshith.py\n",
        "import numpy as np\n",
        "from numba import prange, jit\n",
        "import time\n",
        "\n",
        "@profile\n",
        "def matrix_mul(A, B):\n",
        "  rows_A, cols_A = A.shape\n",
        "  rows_B, cols_B = B.shape\n",
        "\n",
        "  C = np.zeros((rows_A, cols_B))\n",
        "\n",
        "  for i in prange(rows_A):\n",
        "    for j in prange(cols_B):\n",
        "      for k in prange(cols_A):\n",
        "        C[i][j] += A[i][k] * B[k][j]\n",
        "\n",
        "  return C\n",
        "\n",
        "start_time = time.time()\n",
        "A = np.random.rand(5, 5)\n",
        "B = np.random.rand(5, 5)\n",
        "C = matrix_mul(A, B)\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(\"Execution time: {:.6f} seconds\".format(execution_time))\n",
        "print('\\nResult: \\n', C)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsdaYzQH8-jP",
        "outputId": "594bc252-6065-4fee-9328-fd26720521ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting harshith.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kernprof -l harshith.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNPASwQx-dYt",
        "outputId": "5b20e77d-7e0f-437e-ea19-c55e2e3c31b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution time: 0.000786 seconds\n",
            "\n",
            "Result: \n",
            " [[1.71713507 0.60067351 1.02303811 1.11876789 1.68303027]\n",
            " [2.46806613 1.28387016 1.32622231 1.79139634 2.36357834]\n",
            " [0.7445736  0.3445523  0.50744407 0.36034433 0.69746194]\n",
            " [1.41549689 0.71025133 0.75670762 1.12908796 1.15806736]\n",
            " [1.60744284 1.10489936 0.62010194 1.62123415 1.37756766]]\n",
            "Wrote profile results to harshith.py.lprof\n",
            "Inspect results with:\n",
            "python3 -m line_profiler -rmt \"harshith.py.lprof\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m line_profiler -rmt \"harshith.py.lprof\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_6Nl7wg-zm0",
        "outputId": "64f84e6f-fc49-496c-efa9-cac07453d506"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timer unit: 1e-06 s\n",
            "\n",
            "Total time: 0.000487168 s\n",
            "File: harshith.py\n",
            "Function: matrix_mul at line 5\n",
            "\n",
            "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
            "==============================================================\n",
            "     \u001b[1;36m5\u001b[0m                                           \u001b[92;49m@profile\u001b[0m                            \n",
            "     \u001b[1;36m6\u001b[0m                                           \u001b[96;49mdef\u001b[0m\u001b[97;49m \u001b[0m\u001b[92;49mmatrix_mul\u001b[0m\u001b[97;49m(\u001b[0m\u001b[97;49mA\u001b[0m\u001b[97;49m,\u001b[0m\u001b[97;49m \u001b[0m\u001b[97;49mB\u001b[0m\u001b[97;49m)\u001b[0m\u001b[97;49m:\u001b[0m               \n",
            "     \u001b[1;36m7\u001b[0m         \u001b[1;36m1\u001b[0m          \u001b[1;36m4.7\u001b[0m      \u001b[1;36m4.7\u001b[0m      \u001b[1;36m1.0\u001b[0m  \u001b[97;49m  \u001b[0m\u001b[97;49mrows_A\u001b[0m\u001b[97;49m,\u001b[0m\u001b[97;49m \u001b[0m\u001b[97;49mcols_A\u001b[0m\u001b[97;49m \u001b[0m\u001b[91;49m=\u001b[0m\u001b[97;49m \u001b[0m\u001b[97;49mA\u001b[0m\u001b[91;49m.\u001b[0m\u001b[97;49mshape\u001b[0m          \n",
            "     \u001b[1;36m8\u001b[0m         \u001b[1;36m1\u001b[0m          \u001b[1;36m0.8\u001b[0m      \u001b[1;36m0.8\u001b[0m      \u001b[1;36m0.2\u001b[0m  \u001b[97;49m  \u001b[0m\u001b[97;49mrows_B\u001b[0m\u001b[97;49m,\u001b[0m\u001b[97;49m \u001b[0m\u001b[97;49mcols_B\u001b[0m\u001b[97;49m \u001b[0m\u001b[91;49m=\u001b[0m\u001b[97;49m \u001b[0m\u001b[97;49mB\u001b[0m\u001b[91;49m.\u001b[0m\u001b[97;49mshape\u001b[0m          \n",
            "     \u001b[1;36m9\u001b[0m                                                                               \n",
            "    \u001b[1;36m10\u001b[0m         \u001b[1;36m1\u001b[0m          \u001b[1;36m3.5\u001b[0m      \u001b[1;36m3.5\u001b[0m      \u001b[1;36m0.7\u001b[0m  \u001b[97;49m  \u001b[0m\u001b[97;49mC\u001b[0m\u001b[97;49m \u001b[0m\u001b[91;49m=\u001b[0m\u001b[97;49m \u001b[0m\u001b[97;49mnp\u001b[0m\u001b[91;49m.\u001b[0m\u001b[97;49mzeros\u001b[0m\u001b[97;49m(\u001b[0m\u001b[97;49m(\u001b[0m\u001b[97;49mrows_A\u001b[0m\u001b[97;49m,\u001b[0m\u001b[97;49m \u001b[0m\u001b[97;49mcols_B\u001b[0m\u001b[97;49m)\u001b[0m\u001b[97;49m)\u001b[0m    \n",
            "    \u001b[1;36m11\u001b[0m                                                                               \n",
            "    \u001b[1;36m12\u001b[0m         \u001b[1;36m6\u001b[0m         \u001b[1;36m12.5\u001b[0m      \u001b[1;36m2.1\u001b[0m      \u001b[1;36m2.6\u001b[0m  \u001b[97;49m  \u001b[0m\u001b[96;49mfor\u001b[0m\u001b[97;49m \u001b[0m\u001b[97;49mi\u001b[0m\u001b[97;49m \u001b[0m\u001b[91;49min\u001b[0m\u001b[97;49m \u001b[0m\u001b[97;49mprange\u001b[0m\u001b[97;49m(\u001b[0m\u001b[97;49mrows_A\u001b[0m\u001b[97;49m)\u001b[0m\u001b[97;49m:\u001b[0m          \n",
            "    \u001b[1;36m13\u001b[0m        \u001b[1;36m30\u001b[0m         \u001b[1;36m17.0\u001b[0m      \u001b[1;36m0.6\u001b[0m      \u001b[1;36m3.5\u001b[0m  \u001b[97;49m    \u001b[0m\u001b[96;49mfor\u001b[0m\u001b[97;49m \u001b[0m\u001b[97;49mj\u001b[0m\u001b[97;49m \u001b[0m\u001b[91;49min\u001b[0m\u001b[97;49m \u001b[0m\u001b[97;49mprange\u001b[0m\u001b[97;49m(\u001b[0m\u001b[97;49mcols_B\u001b[0m\u001b[97;49m)\u001b[0m\u001b[97;49m:\u001b[0m        \n",
            "    \u001b[1;36m14\u001b[0m       \u001b[1;36m150\u001b[0m         \u001b[1;36m86.2\u001b[0m      \u001b[1;36m0.6\u001b[0m     \u001b[1;36m17.7\u001b[0m  \u001b[97;49m      \u001b[0m\u001b[96;49mfor\u001b[0m\u001b[97;49m \u001b[0m\u001b[97;49mk\u001b[0m\u001b[97;49m \u001b[0m\u001b[91;49min\u001b[0m\u001b[97;49m \u001b[0m\u001b[97;49mprange\u001b[0m\u001b[97;49m(\u001b[0m\u001b[97;49mcols_A\u001b[0m\u001b[97;49m)\u001b[0m\u001b[97;49m:\u001b[0m      \n",
            "    \u001b[1;36m15\u001b[0m       \u001b[1;36m125\u001b[0m        \u001b[1;36m362.1\u001b[0m      \u001b[1;36m2.9\u001b[0m     \u001b[1;36m74.3\u001b[0m  \u001b[97;49m        \u001b[0m\u001b[97;49mC\u001b[0m\u001b[97;49m[\u001b[0m\u001b[97;49mi\u001b[0m\u001b[97;49m]\u001b[0m\u001b[97;49m[\u001b[0m\u001b[97;49mj\u001b[0m\u001b[97;49m]\u001b[0m\u001b[97;49m \u001b[0m\u001b[91;49m+\u001b[0m\u001b[91;49m=\u001b[0m\u001b[97;49m \u001b[0m\u001b[97;49mA\u001b[0m\u001b[97;49m[\u001b[0m\u001b[97;49mi\u001b[0m\u001b[97;49m]\u001b[0m\u001b[97;49m[\u001b[0m\u001b[97;49mk\u001b[0m\u001b[97;49m]\u001b[0m\u001b[97;49m \u001b[0m\u001b[91;49m*\u001b[0m\u001b[97;49m \u001b[0m\u001b[97;49mB\u001b[0m\u001b[97;49m[\u001b[0m\u001b[97;49mk\u001b[0m\u001b[97;49m]\u001b[0m\u001b[97;49m[\u001b[0m\u001b[97;49mj\u001b[0m\u001b[97;49m]\u001b[0m\n",
            "    \u001b[1;36m16\u001b[0m                                                                               \n",
            "    \u001b[1;36m17\u001b[0m         \u001b[1;36m1\u001b[0m          \u001b[1;36m0.3\u001b[0m      \u001b[1;36m0.3\u001b[0m      \u001b[1;36m0.1\u001b[0m  \u001b[97;49m  \u001b[0m\u001b[96;49mreturn\u001b[0m\u001b[97;49m \u001b[0m\u001b[97;49mC\u001b[0m                          \n",
            "\n",
            "\n",
            "  0.00 seconds - harshith.py:5 - matrix_mul\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BgLUSe16IFsO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "74CoMOmtIFTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Numba Diagnostics**\n",
        "A short introduction to the diagnostics generated by the NUMBA compiler.\n",
        "\n",
        "A very usueful document to understand what parallelizing compilers do is the following Survey:\n",
        "\n",
        "[Compiler Transformation for High-Performance Computing](https://www.google.com/url?q=https%3A%2F%2Fengineering.purdue.edu%2F%7Eeigenman%2Fapp%2Fbacon-compiling4hpc.pdf) published in the ACM Computing Surveys in December of 1994. The survey was written by Bacon, Graham and Sharp. We strongly encourage you to read the document before starting to use this notebook. It will give you a framework to understand what the NUMBA parallelizing compiler does to Python code.\n",
        "\n",
        "The next code cells are taken from: [Numba's documentation on diagnostics](https://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics)"
      ],
      "metadata": {
        "id": "AY25CSFUYwf1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The parallel option for jit() can produce diagnostic information about the transforms undertaken in automatically parallelizing the decorated code. This information can be accessed in two ways, the first is by setting the environment variable NUMBA_PARALLEL_DIAGNOSTICS, the second is by calling parallel_diagnostics(), both methods give the same information and print to STDOUT. The level of verbosity in the diagnostic information is controlled by an integer argument of value between 1 and 4 inclusive, 1 being the least verbose and 4 the most. For example:"
      ],
      "metadata": {
        "id": "K6lIjByKZYrS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numba"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zGlNEHFZjGH",
        "outputId": "a23a4177-e938-4b62-b3c3-e7faeef81c2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (0.58.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba) (0.41.1)\n",
            "Requirement already satisfied: numpy<1.27,>=1.22 in /usr/local/lib/python3.10/dist-packages (from numba) (1.25.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Hello Numba')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGAJe3EcazMa",
        "outputId": "a96b8a2c-35a8-4a5d-9eda-7ad845396217"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello Numba\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that when we use NUMBA, we are using two special features that are not part of the regular python language:\n",
        "\n",
        "The decorator njit, which instructs numba to try to parallelize the function that follows.\n",
        "The keyword prange, which has a special meaning in NUMBA, indicating that the for statement where prange is used should be treated as a parallel for loop, not as a regular sequential for loop.\n",
        "Depending on the code in the function, NUMBA might or might not be able to produce parallel code.\n",
        "\n",
        "The diagnostics option in NUMBA provides feedback to the user about the success or failure of the attempt to parallelize."
      ],
      "metadata": {
        "id": "VS7HWnaMbcwl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numba import njit,prange\n",
        "import numpy as np\n",
        "@njit(parallel=True)\n",
        "def test(x):\n",
        "    n = x.shape[0]\n",
        "    a = np.sin(x)\n",
        "    b = np.cos(a * a)\n",
        "    acc = 0\n",
        "    for i in prange(n - 2):\n",
        "        for j in prange(n - 1):\n",
        "            acc += b[i] + b[j + 1]\n",
        "    return acc"
      ],
      "metadata": {
        "id": "UK-HulG2Jyzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = np.arange(10)\n",
        "print(t)\n",
        "test(t)\n",
        "test.parallel_diagnostics(level=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3giZCDi2LcMJ",
        "outputId": "9b1d0b68-2d6a-4a0e-efc2-4f2c5ab0fba0",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 2 3 4 5 6 7 8 9]\n",
            " \n",
            "================================================================================\n",
            " Parallel Accelerator Optimizing:  Function test, <ipython-input-3-d35ef36e144b>\n",
            " (3)  \n",
            "================================================================================\n",
            "\n",
            "\n",
            "Parallel loop listing for  Function test, <ipython-input-3-d35ef36e144b> (3) \n",
            "--------------------------------------|loop #ID\n",
            "@njit(parallel=True)                  | \n",
            "def test(x):                          | \n",
            "    n = x.shape[0]                    | \n",
            "    a = np.sin(x)---------------------| #0\n",
            "    b = np.cos(a * a)-----------------| #1\n",
            "    acc = 0                           | \n",
            "    for i in prange(n - 2):-----------| #3\n",
            "        for j in prange(n - 1):-------| #2\n",
            "            acc += b[i] + b[j + 1]    | \n",
            "    return acc                        | \n",
            "--------------------------------- Fusing loops ---------------------------------\n",
            "Attempting fusion of parallel loops (combines loops with similar properties)...\n",
            "  Trying to fuse loops #0 and #1:\n",
            "    - fusion succeeded: parallel for-loop #1 is fused into for-loop #0.\n",
            "  Trying to fuse loops #0 and #3:\n",
            "    - fusion failed: loop dimension mismatched in axis 0. slice(0, x_size0.1, 1)\n",
            " != slice(0, $46binary_subtract.18, 1)\n",
            "----------------------------- Before Optimisation ------------------------------\n",
            "Parallel region 0:\n",
            "+--0 (parallel)\n",
            "+--1 (parallel)\n",
            "\n",
            "\n",
            "Parallel region 1:\n",
            "+--3 (parallel)\n",
            "   +--2 (parallel)\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "------------------------------ After Optimisation ------------------------------\n",
            "Parallel region 0:\n",
            "+--0 (parallel, fused with loop(s): 1)\n",
            "\n",
            "\n",
            "Parallel region 1:\n",
            "+--3 (parallel)\n",
            "   +--2 (serial)\n",
            "\n",
            "\n",
            " \n",
            "Parallel region 0 (loop #0) had 1 loop(s) fused.\n",
            " \n",
            "Parallel region 1 (loop #3) had 0 loop(s) fused and 1 loop(s) serialized as part\n",
            " of the larger parallel loop (#3).\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            " \n",
            "---------------------------Loop invariant code motion---------------------------\n",
            "Allocation hoisting:\n",
            "No allocation hoisting found\n",
            "\n",
            "Instruction hoisting:\n",
            "loop #0:\n",
            "  Failed to hoist the following:\n",
            "    dependency: $arg_out_var.10 = getitem(value=x, index=$parfor__index_5.105, fn=<built-in function getitem>)\n",
            "    dependency: $14load_method.5.11 = getattr(value=$push_global_to_block.90, attr=sin)\n",
            "    dependency: $expr_out_var.9 = call $14load_method.5.11($arg_out_var.10, func=$14load_method.5.11, args=[Var($arg_out_var.10, <ipython-input-3-d35ef36e144b>:6)], kws=(), vararg=None, varkwarg=None, target=None)\n",
            "    dependency: $arg_out_var.17 = $expr_out_var.9 * $expr_out_var.9\n",
            "    dependency: $24load_method.9.20 = getattr(value=$push_global_to_block.91, attr=cos)\n",
            "    dependency: $expr_out_var.16 = call $24load_method.9.20($arg_out_var.17, func=$24load_method.9.20, args=[Var($arg_out_var.17, <ipython-input-3-d35ef36e144b>:7)], kws=(), vararg=None, varkwarg=None, target=None)\n",
            "loop #3:\n",
            "  Has the following hoisted:\n",
            "    $const60.4 = const(int, 1)\n",
            "    $62binary_subtract.5 = n - $const60.4\n",
            "  Failed to hoist the following:\n",
            "    dependency: acc_3 = acc.2\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To aid users unfamiliar with the transforms undertaken when the parallel option is used, and to assist in the understanding of the subsequent sections, the following definitions are provided:\n",
        "\n",
        "* **Loop fusion**\n",
        "\n",
        "  Loop fusion is a technique whereby loops with equivalent bounds may be combined under certain conditions to produce a loop with a larger body (aiming to improve data locality).\n",
        "\n",
        "* **Loop serialization**\n",
        "\n",
        "  Loop serialization occurs when any number of prange driven loops are present inside another prange driven loop. In this case the outermost of all the prange loops executes in parallel and any inner prange loops (nested or otherwise) are treated as standard range based loops. Essentially, nested parallelism does not occur.\n",
        "\n",
        "* **Loop invariant code motion**\n",
        "\n",
        "  Loop invariant code motion is an optimization technique that analyses a loop to look for statements that can be moved outside the loop body without changing the result of executing the loop, these statements are then “hoisted” out of the loop to save repeated computation.\n",
        "\n",
        "* **Allocation hoisting**\n",
        "\n",
        "  Allocation hoisting is a specialized case of loop invariant code motion that is possible due to the design of some common NumPy allocation methods. Explanation of this technique is best driven by an example:\n"
      ],
      "metadata": {
        "id": "LImet46Mb4N7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@njit(parallel=True)\n",
        "def test(n):\n",
        "    results = np.zeros((n, 50, 50))\n",
        "    for i in prange(n):\n",
        "        temp = np.zeros((50, 50))\n",
        "        for j in range(50):\n",
        "            temp[j, j] = i\n",
        "        results[i] = temp\n",
        "    return results\n",
        "\n",
        "n = 5\n",
        "results = test(n)\n",
        "print(results)\n",
        "# test.parallel_diagnostics(level=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "q4QNwiLNbnvp",
        "outputId": "24e4af3f-3cf1-438f-9264-43deb355cdbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            " [[1. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 1. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 1. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 1. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 1. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 1.]]\n",
            "\n",
            " [[2. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 2. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 2. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 2. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 2. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 2.]]\n",
            "\n",
            " [[3. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 3. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 3. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 3. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 3. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 3.]]\n",
            "\n",
            " [[4. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 4. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 4. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 4. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 4. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 4.]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@njit(parallel=True)\n",
        "def test(n):\n",
        "    for i in prange(n):\n",
        "        temp = np.empty((50, 50))\n",
        "        temp[:] = 0\n",
        "        for j in range(50):\n",
        "            temp[j, j] = i\n",
        "            results[i] = temp\n",
        "    return results"
      ],
      "metadata": {
        "id": "fP7QCmAxeEjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **After Hoisting**"
      ],
      "metadata": {
        "id": "1n91nGC0gjsO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@njit(parallel=True)\n",
        "def test(n):\n",
        "    temp = np.empty((50, 50))\n",
        "    for i in prange(n):\n",
        "        temp[:] = 0\n",
        "        for j in range(50):\n",
        "            temp[j, j] = i\n",
        "            results[i] = temp\n",
        "    return results"
      ],
      "metadata": {
        "id": "bMX9Rt0AgoLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It can be seen that the np.zeros allocation is split into an allocation and an assignment, and then the allocation is hoisted out of the loop in i, this producing more efficient code as the allocation only occurs once."
      ],
      "metadata": {
        "id": "df6_q0bzgyRu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **The parallel diagnostics report sections**\n",
        "\n",
        "1. **Code annotation**\n",
        "\n",
        "  This is the first section and contains the source code of the decorated function with loops that have parallel semantics identified and enumerated. The loop #ID column on the right of the source code lines up with identified parallel loops. From the example, #0 is np.sin, #1 is np.cos and #2 and #3 are prange():"
      ],
      "metadata": {
        "id": "57FIU8RGg45y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@njit(parallel=True)\n",
        "def test(x):\n",
        "    n = x.shape[0]\n",
        "    a = np.sin(x)\n",
        "    b = np.cos(a * a)\n",
        "    acc = 0\n",
        "    for i in prange(n - 2):\n",
        "        for j in prange(n - 1):\n",
        "            acc += b[i] + b[j + 1]\n",
        "    return acc"
      ],
      "metadata": {
        "id": "xiFRoM1xhIbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is worth noting that the loop IDs are enumerated in the order they are discovered which is not necessarily the same order as present in the source. Further, it should also be noted that the parallel transforms use a static counter for loop ID indexing. As a consequence it is possible for the loop ID index to not start at 0 due to use of the same counter for internal optimizations/transforms taking place that are invisible to the user.\n",
        "\n",
        "2. **Fusing loops**\n",
        "\n",
        "  This section describes the attempts made at fusing discovered loops noting which succeeded and which failed. In the case of failure to fuse a reason is given (e.g. dependency on other data). From the example:\n",
        "\n"
      ],
      "metadata": {
        "id": "5EgdpBYmizlU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@njit(parallel=True)\n",
        "def fused_test(x):\n",
        "    n = x.shape[0]\n",
        "    a = np.sin(x)\n",
        "    b = np.cos(a * a)\n",
        "    acc = 0\n",
        "    for i in prange(n - 2):\n",
        "        for j in prange(n - 1):\n",
        "            acc += b[i] + b[j + 1]\n",
        "    return acc\n",
        "\n",
        "x = np.arange(10)\n",
        "fused_test(x)\n",
        "fused_test.parallel_diagnostics(level=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "pDpA2Yr5i_Mi",
        "outputId": "b3dc3421-66e1-478d-cd51-1368f68c2e1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "================================================================================\n",
            " Parallel Accelerator Optimizing:  Function fused_test, <ipython-\n",
            "input-20-70044bb7d342> (1)  \n",
            "================================================================================\n",
            "\n",
            "\n",
            "Parallel loop listing for  Function fused_test, <ipython-input-20-70044bb7d342> (1) \n",
            "--------------------------------------|loop #ID\n",
            "@njit(parallel=True)                  | \n",
            "def fused_test(x):                    | \n",
            "    n = x.shape[0]                    | \n",
            "    a = np.sin(x)---------------------| #24\n",
            "    b = np.cos(a * a)-----------------| #25\n",
            "    acc = 0                           | \n",
            "    for i in prange(n - 2):-----------| #27\n",
            "        for j in prange(n - 1): ------| #26\n",
            "            acc += b[i] + b[j + 1]    | \n",
            "    return acc                        | \n",
            "--------------------------------- Fusing loops ---------------------------------\n",
            "Attempting fusion of parallel loops (combines loops with similar properties)...\n",
            "  Trying to fuse loops #24 and #25:\n",
            "    - fusion succeeded: parallel for-loop #25 is fused into for-loop #24.\n",
            "  Trying to fuse loops #24 and #27:\n",
            "    - fusion failed: loop dimension mismatched in axis 0. slice(0, x_size0.921, \n",
            "1) != slice(0, $46binary_subtract.18, 1)\n",
            "----------------------------- Before Optimisation ------------------------------\n",
            "Parallel region 0:\n",
            "+--24 (parallel)\n",
            "+--25 (parallel)\n",
            "\n",
            "\n",
            "Parallel region 1:\n",
            "+--27 (parallel)\n",
            "   +--26 (parallel)\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "------------------------------ After Optimisation ------------------------------\n",
            "Parallel region 0:\n",
            "+--24 (parallel, fused with loop(s): 25)\n",
            "\n",
            "\n",
            "Parallel region 1:\n",
            "+--27 (parallel)\n",
            "   +--26 (serial)\n",
            "\n",
            "\n",
            " \n",
            "Parallel region 0 (loop #24) had 1 loop(s) fused.\n",
            " \n",
            "Parallel region 1 (loop #27) had 0 loop(s) fused and 1 loop(s) serialized as \n",
            "part of the larger parallel loop (#27).\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            " \n",
            "---------------------------Loop invariant code motion---------------------------\n",
            "Allocation hoisting:\n",
            "No allocation hoisting found\n",
            "\n",
            "Instruction hoisting:\n",
            "loop #24:\n",
            "  Failed to hoist the following:\n",
            "    dependency: $arg_out_var.930 = getitem(value=x, index=$parfor__index_925.1025, fn=<built-in function getitem>)\n",
            "    dependency: $14load_method.5.931 = getattr(value=$push_global_to_block.1010, attr=sin)\n",
            "    dependency: $expr_out_var.929 = call $14load_method.5.931($arg_out_var.930, func=$14load_method.5.931, args=[Var($arg_out_var.930, <ipython-input-20-70044bb7d342>:4)], kws=(), vararg=None, varkwarg=None, target=None)\n",
            "    dependency: $arg_out_var.937 = $expr_out_var.929 * $expr_out_var.929\n",
            "    dependency: $24load_method.9.940 = getattr(value=$push_global_to_block.1011, attr=cos)\n",
            "    dependency: $expr_out_var.936 = call $24load_method.9.940($arg_out_var.937, func=$24load_method.9.940, args=[Var($arg_out_var.937, <ipython-input-20-70044bb7d342>:5)], kws=(), vararg=None, varkwarg=None, target=None)\n",
            "loop #27:\n",
            "  Has the following hoisted:\n",
            "    $const60.4 = const(int, 1)\n",
            "    $62binary_subtract.5 = n - $const60.4\n",
            "  Failed to hoist the following:\n",
            "    dependency: acc_3 = acc.2\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It can be seen that fusion of loops #0 and #1 was attempted and this succeeded (both are based on the same dimensions of x). Following the successful fusion of #0 and #1, fusion was attempted between #0 (now including the fused #1 loop) and #3. This fusion failed because there is a loop dimension mismatch, #0 is size x.shape whereas #3 is size x.shape[0] - 2.\n",
        "\n",
        "3. **Before Optimization**\n",
        "\n",
        "  This section shows the structure of the parallel regions in the code before any optimization has taken place, but with loops associated with their final parallel region (this is to make before/after optimization output directly comparable). Multiple parallel regions may exist if there are loops which cannot be fused, in this case code within each region will execute in parallel, but each parallel region will run sequentially. From the example:\n",
        "\n"
      ],
      "metadata": {
        "id": "wmFmcCkiEvLK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@njit(parallel=True)\n",
        "def test(x):\n",
        "    n = x.shape[0]\n",
        "    a = np.sin(x)\n",
        "    b = np.cos(a * a)\n",
        "    acc = 0\n",
        "    for i in prange(n - 2):\n",
        "        for j in prange(n - 1):\n",
        "            acc += b[i] + b[j + 1]\n",
        "    return acc\n",
        "\n",
        "x = np.arange(10)\n",
        "test(x)\n",
        "test.parallel_diagnostics(level=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "M8OcChiGG2uA",
        "outputId": "207af6c9-37da-4622-f8e3-651006ab02d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "================================================================================\n",
            " Parallel Accelerator Optimizing:  Function test, <ipython-\n",
            "input-22-81c91a65f043> (1)  \n",
            "================================================================================\n",
            "\n",
            "\n",
            "Parallel loop listing for  Function test, <ipython-input-22-81c91a65f043> (1) \n",
            "--------------------------------------|loop #ID\n",
            "@njit(parallel=True)                  | \n",
            "def test(x):                          | \n",
            "    n = x.shape[0]                    | \n",
            "    a = np.sin(x)---------------------| #32\n",
            "    b = np.cos(a * a)-----------------| #33\n",
            "    acc = 0                           | \n",
            "    for i in prange(n - 2):-----------| #35\n",
            "        for j in prange(n - 1): ------| #34\n",
            "            acc += b[i] + b[j + 1]    | \n",
            "    return acc                        | \n",
            "--------------------------------- Fusing loops ---------------------------------\n",
            "Attempting fusion of parallel loops (combines loops with similar properties)...\n",
            "  Trying to fuse loops #32 and #33:\n",
            "    - fusion succeeded: parallel for-loop #33 is fused into for-loop #32.\n",
            "  Trying to fuse loops #32 and #35:\n",
            "    - fusion failed: loop dimension mismatched in axis 0. slice(0, x_size0.1169,\n",
            " 1) != slice(0, $46binary_subtract.18, 1)\n",
            "----------------------------- Before Optimisation ------------------------------\n",
            "Parallel region 0:\n",
            "+--32 (parallel)\n",
            "+--33 (parallel)\n",
            "\n",
            "\n",
            "Parallel region 1:\n",
            "+--35 (parallel)\n",
            "   +--34 (parallel)\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "------------------------------ After Optimisation ------------------------------\n",
            "Parallel region 0:\n",
            "+--32 (parallel, fused with loop(s): 33)\n",
            "\n",
            "\n",
            "Parallel region 1:\n",
            "+--35 (parallel)\n",
            "   +--34 (serial)\n",
            "\n",
            "\n",
            " \n",
            "Parallel region 0 (loop #32) had 1 loop(s) fused.\n",
            " \n",
            "Parallel region 1 (loop #35) had 0 loop(s) fused and 1 loop(s) serialized as \n",
            "part of the larger parallel loop (#35).\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            " \n",
            "---------------------------Loop invariant code motion---------------------------\n",
            "Allocation hoisting:\n",
            "No allocation hoisting found\n",
            "\n",
            "Instruction hoisting:\n",
            "loop #32:\n",
            "  Failed to hoist the following:\n",
            "    dependency: $arg_out_var.1178 = getitem(value=x, index=$parfor__index_1173.1273, fn=<built-in function getitem>)\n",
            "    dependency: $14load_method.5.1179 = getattr(value=$push_global_to_block.1258, attr=sin)\n",
            "    dependency: $expr_out_var.1177 = call $14load_method.5.1179($arg_out_var.1178, func=$14load_method.5.1179, args=[Var($arg_out_var.1178, <ipython-input-22-81c91a65f043>:4)], kws=(), vararg=None, varkwarg=None, target=None)\n",
            "    dependency: $arg_out_var.1185 = $expr_out_var.1177 * $expr_out_var.1177\n",
            "    dependency: $24load_method.9.1188 = getattr(value=$push_global_to_block.1259, attr=cos)\n",
            "    dependency: $expr_out_var.1184 = call $24load_method.9.1188($arg_out_var.1185, func=$24load_method.9.1188, args=[Var($arg_out_var.1185, <ipython-input-22-81c91a65f043>:5)], kws=(), vararg=None, varkwarg=None, target=None)\n",
            "loop #35:\n",
            "  Has the following hoisted:\n",
            "    $const60.4 = const(int, 1)\n",
            "    $62binary_subtract.5 = n - $const60.4\n",
            "  Failed to hoist the following:\n",
            "    dependency: acc_3 = acc.2\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As alluded to by the Fusing loops section, there are necessarily two parallel regions in the code. The first contains loops #0 and #1, the second contains #3 and #2, all loops are marked parallel as no optimization has taken place yet.\n",
        "\n",
        "4. **After Optimization**\n",
        "\n",
        "  This section shows the structure of the parallel regions in the code after optimization has taken place. Again, parallel regions are enumerated with their corresponding loops but this time loops which are fused or serialized are noted and a summary is presented. From the example:"
      ],
      "metadata": {
        "id": "nAYAGRo4Gn8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@njit(parallel=True)\n",
        "def test(x):\n",
        "    n = x.shape[0]\n",
        "    a = np.sin(x)\n",
        "    b = np.cos(a * a)\n",
        "    acc = 0\n",
        "    for i in prange(n - 2):\n",
        "        for j in prange(n - 1):\n",
        "            acc += b[i] + b[j + 1]\n",
        "    return acc\n",
        "\n",
        "x = np.arange(10)\n",
        "test(x)\n",
        "test.parallel_diagnostics(level=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4p1Ktn0OGrif",
        "outputId": "f8976564-a473-4538-8bda-ff9ee43272ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "================================================================================\n",
            " Parallel Accelerator Optimizing:  Function test, <ipython-\n",
            "input-23-81c91a65f043> (1)  \n",
            "================================================================================\n",
            "\n",
            "\n",
            "Parallel loop listing for  Function test, <ipython-input-23-81c91a65f043> (1) \n",
            "--------------------------------------|loop #ID\n",
            "@njit(parallel=True)                  | \n",
            "def test(x):                          | \n",
            "    n = x.shape[0]                    | \n",
            "    a = np.sin(x)---------------------| #36\n",
            "    b = np.cos(a * a)-----------------| #37\n",
            "    acc = 0                           | \n",
            "    for i in prange(n - 2):-----------| #39\n",
            "        for j in prange(n - 1): ------| #38\n",
            "            acc += b[i] + b[j + 1]    | \n",
            "    return acc                        | \n",
            "--------------------------------- Fusing loops ---------------------------------\n",
            "Attempting fusion of parallel loops (combines loops with similar properties)...\n",
            "  Trying to fuse loops #36 and #37:\n",
            "    - fusion succeeded: parallel for-loop #37 is fused into for-loop #36.\n",
            "  Trying to fuse loops #36 and #39:\n",
            "    - fusion failed: loop dimension mismatched in axis 0. slice(0, x_size0.1293,\n",
            " 1) != slice(0, $46binary_subtract.18, 1)\n",
            "----------------------------- Before Optimisation ------------------------------\n",
            "Parallel region 0:\n",
            "+--36 (parallel)\n",
            "+--37 (parallel)\n",
            "\n",
            "\n",
            "Parallel region 1:\n",
            "+--39 (parallel)\n",
            "   +--38 (parallel)\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "------------------------------ After Optimisation ------------------------------\n",
            "Parallel region 0:\n",
            "+--36 (parallel, fused with loop(s): 37)\n",
            "\n",
            "\n",
            "Parallel region 1:\n",
            "+--39 (parallel)\n",
            "   +--38 (serial)\n",
            "\n",
            "\n",
            " \n",
            "Parallel region 0 (loop #36) had 1 loop(s) fused.\n",
            " \n",
            "Parallel region 1 (loop #39) had 0 loop(s) fused and 1 loop(s) serialized as \n",
            "part of the larger parallel loop (#39).\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            " \n",
            "---------------------------Loop invariant code motion---------------------------\n",
            "Allocation hoisting:\n",
            "No allocation hoisting found\n",
            "\n",
            "Instruction hoisting:\n",
            "loop #36:\n",
            "  Failed to hoist the following:\n",
            "    dependency: $arg_out_var.1302 = getitem(value=x, index=$parfor__index_1297.1397, fn=<built-in function getitem>)\n",
            "    dependency: $14load_method.5.1303 = getattr(value=$push_global_to_block.1382, attr=sin)\n",
            "    dependency: $expr_out_var.1301 = call $14load_method.5.1303($arg_out_var.1302, func=$14load_method.5.1303, args=[Var($arg_out_var.1302, <ipython-input-23-81c91a65f043>:4)], kws=(), vararg=None, varkwarg=None, target=None)\n",
            "    dependency: $arg_out_var.1309 = $expr_out_var.1301 * $expr_out_var.1301\n",
            "    dependency: $24load_method.9.1312 = getattr(value=$push_global_to_block.1383, attr=cos)\n",
            "    dependency: $expr_out_var.1308 = call $24load_method.9.1312($arg_out_var.1309, func=$24load_method.9.1312, args=[Var($arg_out_var.1309, <ipython-input-23-81c91a65f043>:5)], kws=(), vararg=None, varkwarg=None, target=None)\n",
            "loop #39:\n",
            "  Has the following hoisted:\n",
            "    $const60.4 = const(int, 1)\n",
            "    $62binary_subtract.5 = n - $const60.4\n",
            "  Failed to hoist the following:\n",
            "    dependency: acc_3 = acc.2\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It can be noted that parallel region 0 contains loop #0 and, as seen in the fusing loops section, loop #1 is fused into loop #0. It can also be noted that parallel region 1 contains loop #3 and that loop #2 (the inner prange()) has been serialized for execution in the body of loop #3.\n",
        "\n",
        "5. **Loop invariant code motion**\n",
        "\n",
        "  This section shows for each loop, after optimization has occurred:\n",
        "\n",
        "  * The instructions that failed to be hoisted and the reason for failure\n",
        "(dependency/impure).\n",
        "\n",
        "  * The instructions that were hoisted.\n",
        "\n",
        "  * Any allocation hoisting that may have occurred.\n",
        "\n",
        "  From the example:"
      ],
      "metadata": {
        "id": "ouQqJeRQHPYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@njit(parallel=True)\n",
        "def test(x):\n",
        "    n = x.shape[0]\n",
        "    a = np.sin(x)\n",
        "    b = np.cos(a * a)\n",
        "    acc = 0\n",
        "    for i in prange(n - 2):\n",
        "        for j in prange(n - 1):\n",
        "            acc += b[i] + b[j + 1]\n",
        "    return acc\n",
        "\n",
        "x = np.arange(10)\n",
        "test(x)\n",
        "test.parallel_diagnostics(level=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bXWUKwczHufG",
        "outputId": "d52a7133-8260-4d0b-d21a-1e46e1ac1777"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "================================================================================\n",
            " Parallel Accelerator Optimizing:  Function test, <ipython-\n",
            "input-24-81c91a65f043> (1)  \n",
            "================================================================================\n",
            "\n",
            "\n",
            "Parallel loop listing for  Function test, <ipython-input-24-81c91a65f043> (1) \n",
            "--------------------------------------|loop #ID\n",
            "@njit(parallel=True)                  | \n",
            "def test(x):                          | \n",
            "    n = x.shape[0]                    | \n",
            "    a = np.sin(x)---------------------| #40\n",
            "    b = np.cos(a * a)-----------------| #41\n",
            "    acc = 0                           | \n",
            "    for i in prange(n - 2):-----------| #43\n",
            "        for j in prange(n - 1): ------| #42\n",
            "            acc += b[i] + b[j + 1]    | \n",
            "    return acc                        | \n",
            "--------------------------------- Fusing loops ---------------------------------\n",
            "Attempting fusion of parallel loops (combines loops with similar properties)...\n",
            "  Trying to fuse loops #40 and #41:\n",
            "    - fusion succeeded: parallel for-loop #41 is fused into for-loop #40.\n",
            "  Trying to fuse loops #40 and #43:\n",
            "    - fusion failed: loop dimension mismatched in axis 0. slice(0, x_size0.1417,\n",
            " 1) != slice(0, $46binary_subtract.18, 1)\n",
            "----------------------------- Before Optimisation ------------------------------\n",
            "Parallel region 0:\n",
            "+--40 (parallel)\n",
            "+--41 (parallel)\n",
            "\n",
            "\n",
            "Parallel region 1:\n",
            "+--43 (parallel)\n",
            "   +--42 (parallel)\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "------------------------------ After Optimisation ------------------------------\n",
            "Parallel region 0:\n",
            "+--40 (parallel, fused with loop(s): 41)\n",
            "\n",
            "\n",
            "Parallel region 1:\n",
            "+--43 (parallel)\n",
            "   +--42 (serial)\n",
            "\n",
            "\n",
            " \n",
            "Parallel region 0 (loop #40) had 1 loop(s) fused.\n",
            " \n",
            "Parallel region 1 (loop #43) had 0 loop(s) fused and 1 loop(s) serialized as \n",
            "part of the larger parallel loop (#43).\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            " \n",
            "---------------------------Loop invariant code motion---------------------------\n",
            "Allocation hoisting:\n",
            "No allocation hoisting found\n",
            "\n",
            "Instruction hoisting:\n",
            "loop #40:\n",
            "  Failed to hoist the following:\n",
            "    dependency: $arg_out_var.1426 = getitem(value=x, index=$parfor__index_1421.1521, fn=<built-in function getitem>)\n",
            "    dependency: $14load_method.5.1427 = getattr(value=$push_global_to_block.1506, attr=sin)\n",
            "    dependency: $expr_out_var.1425 = call $14load_method.5.1427($arg_out_var.1426, func=$14load_method.5.1427, args=[Var($arg_out_var.1426, <ipython-input-24-81c91a65f043>:4)], kws=(), vararg=None, varkwarg=None, target=None)\n",
            "    dependency: $arg_out_var.1433 = $expr_out_var.1425 * $expr_out_var.1425\n",
            "    dependency: $24load_method.9.1436 = getattr(value=$push_global_to_block.1507, attr=cos)\n",
            "    dependency: $expr_out_var.1432 = call $24load_method.9.1436($arg_out_var.1433, func=$24load_method.9.1436, args=[Var($arg_out_var.1433, <ipython-input-24-81c91a65f043>:5)], kws=(), vararg=None, varkwarg=None, target=None)\n",
            "loop #43:\n",
            "  Has the following hoisted:\n",
            "    $const60.4 = const(int, 1)\n",
            "    $62binary_subtract.5 = n - $const60.4\n",
            "  Failed to hoist the following:\n",
            "    dependency: acc_3 = acc.2\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first thing to note is that this information is for advanced users as it refers to the Numba IR of the function being transformed. As an example, the expression a * a in the example source partly translates to the expression $arg_out_var.17 = $expr_out_var.9 * $expr_out_var.9 in the IR, this clearly cannot be hoisted out of loop #0 because it is not loop invariant! Whereas in loop #3, the expression $const58.3 = const(int, 1) comes from the source b[j + 1], the number 1 is clearly a constant and so can be hoisted out of the loop."
      ],
      "metadata": {
        "id": "QmouQQbMIAL4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sample Code Snippets**"
      ],
      "metadata": {
        "id": "AP0sB9IUKW6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numba import njit, prange\n",
        "\n",
        "@njit(parallel=True)\n",
        "def square_elements(arr):\n",
        "    for i in prange(arr.shape[0]):\n",
        "        arr[i] = arr[i] ** 2\n",
        "\n",
        "arr = np.array([1, 2, 3, 4, 5])\n",
        "square_elements(arr)\n",
        "print(arr)\n",
        "square_elements.parallel_diagnostics(level=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhL5NPgzKanO",
        "outputId": "c9921922-5f64-4065-c734-49c95cd0ea46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1  4  9 16 25]\n",
            " \n",
            "================================================================================\n",
            " Parallel Accelerator Optimizing:  Function square_elements, <ipython-\n",
            "input-4-946b419b96e4> (4)  \n",
            "================================================================================\n",
            "\n",
            "\n",
            "Parallel loop listing for  Function square_elements, <ipython-input-4-946b419b96e4> (4) \n",
            "--------------------------------------|loop #ID\n",
            "@njit(parallel=True)                  | \n",
            "def square_elements(arr):             | \n",
            "    for i in prange(arr.shape[0]):----| #3\n",
            "        arr[i] = arr[i] ** 2          | \n",
            "--------------------------------- Fusing loops ---------------------------------\n",
            "Attempting fusion of parallel loops (combines loops with similar properties)...\n",
            "----------------------------- Before Optimisation ------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "------------------------------ After Optimisation ------------------------------\n",
            "Parallel structure is already optimal.\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            " \n",
            "---------------------------Loop invariant code motion---------------------------\n",
            "Allocation hoisting:\n",
            "No allocation hoisting found\n",
            "\n",
            "Instruction hoisting:\n",
            "loop #3:\n",
            "  Has the following hoisted:\n",
            "    $const26.5 = const(int, 2)\n",
            "  Failed to hoist the following:\n",
            "    dependency: $24binary_subscr.4 = getitem(value=arr, index=$parfor__index_65.80, fn=<built-in function getitem>)\n",
            "    dependency: $28binary_power.6 = $24binary_subscr.4 ** $const26.5\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numba import njit, prange\n",
        "import numpy as np\n",
        "\n",
        "@njit(parallel=True)\n",
        "def parallel_multiply(a, b):\n",
        "    result = np.zeros_like(a)\n",
        "    for i in prange(a.shape[0]):\n",
        "        result[i] = a[i] * b[i]\n",
        "    return result\n",
        "\n",
        "a = np.array([1, 2, 3, 4, 5])\n",
        "b = np.array([5, 4, 3, 2, 1])\n",
        "result = parallel_multiply(a, b)\n",
        "print(\"Result:\", result)\n",
        "parallel_multiply.parallel_diagnostics(level=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgPoErmFQRj4",
        "outputId": "351f5339-4c15-45b5-ade2-a5a2a114aeaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result: [5 8 9 8 5]\n",
            " \n",
            "================================================================================\n",
            " Parallel Accelerator Optimizing:  Function parallel_multiply, <ipython-\n",
            "input-5-2320cfa799ca> (4)  \n",
            "================================================================================\n",
            "\n",
            "\n",
            "Parallel loop listing for  Function parallel_multiply, <ipython-input-5-2320cfa799ca> (4) \n",
            "------------------------------------|loop #ID\n",
            "@njit(parallel=True)                | \n",
            "def parallel_multiply(a, b):        | \n",
            "    result = np.zeros_like(a)       | \n",
            "    for i in prange(a.shape[0]):----| #4\n",
            "        result[i] = a[i] * b[i]     | \n",
            "    return result                   | \n",
            "--------------------------------- Fusing loops ---------------------------------\n",
            "Attempting fusion of parallel loops (combines loops with similar properties)...\n",
            "----------------------------- Before Optimisation ------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "------------------------------ After Optimisation ------------------------------\n",
            "Parallel structure is already optimal.\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            " \n",
            "---------------------------Loop invariant code motion---------------------------\n",
            "Allocation hoisting:\n",
            "No allocation hoisting found\n",
            "\n",
            "Instruction hoisting:\n",
            "loop #4:\n",
            "  Failed to hoist the following:\n",
            "    dependency: $34binary_subscr.4 = getitem(value=a, index=$parfor__index_87.102, fn=<built-in function getitem>)\n",
            "    dependency: $40binary_subscr.7 = getitem(value=b, index=$parfor__index_87.102, fn=<built-in function getitem>)\n",
            "    dependency: $42binary_multiply.8 = $34binary_subscr.4 * $40binary_subscr.7\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numba import njit, prange\n",
        "import numpy as np\n",
        "\n",
        "@njit(parallel=True)\n",
        "def parallel_sort(arr):\n",
        "    for i in prange(len(arr) - 1):\n",
        "        for j in range(i + 1, len(arr)):\n",
        "            if arr[i] > arr[j]:\n",
        "                arr[i], arr[j] = arr[j], arr[i]\n",
        "    return arr\n",
        "\n",
        "arr = np.array([5, 2, 9, 1, 5, 6, 3])\n",
        "result = parallel_sort(arr.copy())\n",
        "print(\"Sorted Array:\", result)\n",
        "parallel_sort.parallel_diagnostics(level=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tW5VVkkWQtJf",
        "outputId": "fad8ca46-93b3-4a74-a7ed-be91676e2315"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sorted Array: [1 2 3 5 5 6 9]\n",
            " \n",
            "================================================================================\n",
            " Parallel Accelerator Optimizing:  Function parallel_sort, <ipython-\n",
            "input-6-e346758eb564> (4)  \n",
            "================================================================================\n",
            "\n",
            "\n",
            "Parallel loop listing for  Function parallel_sort, <ipython-input-6-e346758eb564> (4) \n",
            "---------------------------------------------------|loop #ID\n",
            "@njit(parallel=True)                               | \n",
            "def parallel_sort(arr):                            | \n",
            "    for i in prange(len(arr) - 1):-----------------| #5\n",
            "        for j in range(i + 1, len(arr)):           | \n",
            "            if arr[i] > arr[j]:                    | \n",
            "                arr[i], arr[j] = arr[j], arr[i]    | \n",
            "    return arr                                     | \n",
            "--------------------------------- Fusing loops ---------------------------------\n",
            "Attempting fusion of parallel loops (combines loops with similar properties)...\n",
            "----------------------------- Before Optimisation ------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "------------------------------ After Optimisation ------------------------------\n",
            "Parallel structure is already optimal.\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            " \n",
            "---------------------------Loop invariant code motion---------------------------\n",
            "Allocation hoisting:\n",
            "No allocation hoisting found\n",
            "\n",
            "Instruction hoisting:\n",
            "loop #5:\n",
            "  Has the following hoisted:\n",
            "    bool58 = global(bool: <class 'bool'>)\n",
            "    $22load_global.2 = global(range: <class 'range'>)\n",
            "    $const26.4 = const(int, 1)\n",
            "  Failed to hoist the following:\n",
            "    dependency: $40for_iter.2 = iternext(value=$38get_iter.10)\n",
            "    dependency: $j.109 = pair_first(value=$40for_iter.2)\n",
            "    dependency: $40for_iter.4 = pair_second(value=$40for_iter.2)\n",
            "    dependency: $48binary_subscr.5 = getitem(value=arr, index=$parfor__index_106.125, fn=<built-in function getitem>)\n",
            "    dependency: $54binary_subscr.8 = getitem(value=arr, index=$j.109, fn=<built-in function getitem>)\n",
            "    dependency: $56compare_op.9 = $48binary_subscr.5 > $54binary_subscr.8\n",
            "    dependency: $58pred = call $push_global_to_block.123($56compare_op.9, func=$push_global_to_block.123, args=(Var($56compare_op.9, <ipython-input-6-e346758eb564>:8),), kws=(), vararg=None, varkwarg=None, target=None)\n",
            "    dependency: i = $parfor__index_106.125\n",
            "    dependency: $28binary_add.5 = $parfor__index_106.125 + $const26.4\n",
            "    dependency: $36call_function.9 = call $push_global_to_block.124($28binary_add.5, arr__size0_105, func=$push_global_to_block.124, args=[Var($28binary_add.5, <ipython-input-6-e346758eb564>:7), Var(arr__size0_105, <ipython-input-6-e346758eb564>:4)], kws=(), vararg=None, varkwarg=None, target=None)\n",
            "    dependency: $38get_iter.10 = getiter(value=$36call_function.9)\n",
            "    dependency: $64binary_subscr.4 = getitem(value=arr, index=$j.109, fn=<built-in function getitem>)\n",
            "    dependency: $70binary_subscr.7 = getitem(value=arr, index=$parfor__index_106.125, fn=<built-in function getitem>)\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}